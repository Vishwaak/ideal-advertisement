{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037eebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.types import VideoSegment\n",
    "from twelvelabs.embed import TasksStatusResponse\n",
    "\n",
    "from twelvelabs.indexes import IndexesCreateRequestModelsItem\n",
    "from twelvelabs.tasks import TasksRetrieveResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37d31a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1db9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3d2aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = client.indexes.retrieve(index_id=\"68e1830166ecb2513d7eee5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f1290ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = \"https://api.twelvelabs.io/v1.3/tasks\"\n",
    "\n",
    "# files = { \"video_file\": open('goal2-gk0xusut_YK88uF39.mp4', 'rb') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "614fc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"index_id\": \"68e1830166ecb2513d7eee5f\",\n",
    "}\n",
    "headers = {\"x-api-key\": TL_API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e56d831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'video_file_broken', 'message': 'Unable to process video file. Please check if the file is valid and try again.'}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url, data=payload, files=files, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c60b52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0659ff73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result ID: 5cfd4b94-815d-468f-9ed7-c5ea0b95ddca\n",
      "Title: Number 7's Goal: A Celebratory Moment on the Soccer Field\n",
      "Topics:\n",
      "  - Soccer Game Highlights\n",
      "Hashtags:\n",
      "  - Soccer\n",
      "  - Goal\n",
      "  - Teamwork\n",
      "  - Celebration\n",
      "  - Uniforms\n",
      "Output tokens: 30\n"
     ]
    }
   ],
   "source": [
    "result = client.gist(\n",
    "    video_id=SPORTS_VIDEO_ID,\n",
    "    types=[\"title\", \"topic\", \"hashtag\"]\n",
    ")\n",
    "print(\"Result ID:\", result.id)\n",
    "\n",
    "if result.title is not None:\n",
    "    print(\"Title:\", result.title)\n",
    "\n",
    "if result.topics is not None:\n",
    "    print(\"Topics:\")\n",
    "    for topic in result.topics:\n",
    "        print(f\"  - {topic}\")\n",
    "\n",
    "if result.hashtags is not None:\n",
    "    print(\"Hashtags:\")\n",
    "    for hashtag in result.hashtags:\n",
    "        print(f\"  - {hashtag}\")\n",
    "\n",
    "if result.usage is not None:\n",
    "    print(f\"Output tokens: {result.usage.output_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72e6fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream started\n",
      "The video can be broken down into the following main events with corresponding timestamps:\n",
      "\n",
      "- **Application Begins (00:00 - 00:04):** The video starts with a close-up shot of a person's lips as a makeup brush with red lipstick begins to apply the product to the lower lip.\n",
      "- **Continued Application (00:05 - 00:12):** The brush continues to apply the lipstick, moving from the center of the lower lip towards the outer edge.\n",
      "- **Upper Lip Application (00:13 - 00:20):** The brush then moves to the upper lip, applying the lipstick from the center outwards.\n",
      "- **Final Touches (00:21 - 00:24):** The brush applies the last touches of lipstick to the upper lip, completing the application process. The video ends with the lips fully coated in red lipstick.\n",
      "Stream ended\n",
      "Metadata: generation_id='e0e10b18-8036-4202-afaa-c03e9ed85970' usage=TokenUsage(output_tokens=193)\n"
     ]
    }
   ],
   "source": [
    "from twelvelabs import TwelveLabs\n",
    "\n",
    "response = client.analyze_stream(\n",
    "    video_id=AD2_ID,\n",
    "    prompt=\"Break down the video by main event and timestamp\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if hasattr(chunk, 'event_type'):\n",
    "        if chunk.event_type == \"stream_start\":\n",
    "            print(\"Stream started\")\n",
    "        elif chunk.event_type == \"text_generation\":\n",
    "            print(chunk.text, end=\"\")\n",
    "        elif chunk.event_type == \"stream_end\":\n",
    "            print(\"\\nStream ended\")\n",
    "            if chunk.metadata:\n",
    "                print(f\"Metadata: {chunk.metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59e12add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twelvelabs import TwelveLabs\n",
    "from typing import List\n",
    "from twelvelabs.types import VideoSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12af1d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9170fa11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def give_video_embedding(index_id,video_id):\n",
    "    data = client.indexes.videos.retrieve(index_id, video_id, embedding_option=[\"visual-text\", \"audio\"])\n",
    "\n",
    "    return data.embedding.video_embedding.segments[0].float_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "920fe67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.embedding.video_embedding.segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82c8a80f",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "headers: {'date': 'Sat, 04 Oct 2025 21:53:10 GMT', 'content-type': 'application/json; charset=UTF-8', 'content-length': '125', 'connection': 'keep-alive', 'tl-report': 'backend', 'vary': 'Accept-Encoding', 'x-trace-id': '4207796441159854403', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, status_code: 400, body: {'code': 'parameter_invalid', 'message': 'The index_id parameter is invalid. <YOUR_INDEX_ID> is not a valid id type'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Retrieve the embeddings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<YOUR_INDEX_ID>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<YOUR_VIDEO_ID>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_option\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvisual-text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 2. Process the results\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_segments\u001b[39m(segments: List[VideoSegment], max_elements: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\twelvelabs\\indexes\\videos\\client.py:226\u001b[0m, in \u001b[0;36mVideosClient.retrieve\u001b[1;34m(self, index_id, video_id, embedding_option, transcription, request_options)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    170\u001b[0m     index_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m     request_options: typing\u001b[38;5;241m.\u001b[39mOptional[RequestOptions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VideosRetrieveResponse:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    This method retrieves information about the specified video.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     _response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_option\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtranscription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranscription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\twelvelabs\\indexes\\videos\\raw_client.py:264\u001b[0m, in \u001b[0;36mRawVideosClient.retrieve\u001b[1;34m(self, index_id, video_id, embedding_option, transcription, request_options)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(response\u001b[38;5;241m=\u001b[39m_response, data\u001b[38;5;241m=\u001b[39m_data)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[0;32m    265\u001b[0m         headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders),\n\u001b[0;32m    266\u001b[0m         body\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m    267\u001b[0m             typing\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m    268\u001b[0m             parse_obj_as(\n\u001b[0;32m    269\u001b[0m                 type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    270\u001b[0m                 object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[0;32m    271\u001b[0m             ),\n\u001b[0;32m    272\u001b[0m         ),\n\u001b[0;32m    273\u001b[0m     )\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[0;32m    276\u001b[0m         headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders),\n\u001b[0;32m    277\u001b[0m         body\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m         ),\n\u001b[0;32m    284\u001b[0m     )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: headers: {'date': 'Sat, 04 Oct 2025 21:53:10 GMT', 'content-type': 'application/json; charset=UTF-8', 'content-length': '125', 'connection': 'keep-alive', 'tl-report': 'backend', 'vary': 'Accept-Encoding', 'x-trace-id': '4207796441159854403', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, status_code: 400, body: {'code': 'parameter_invalid', 'message': 'The index_id parameter is invalid. <YOUR_INDEX_ID> is not a valid id type'}"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Retrieve the embeddings\n",
    "video = client.indexes.videos.retrieve(index_id=\"<YOUR_INDEX_ID>\", video_id=\"<YOUR_VIDEO_ID>\", embedding_option=[\"visual-text\"])\n",
    "\n",
    "\n",
    "# 2. Process the results\n",
    "def print_segments(segments: List[VideoSegment], max_elements: int = 5):\n",
    "    for segment in segments:\n",
    "        print(f\"  embedding_scope={segment.embedding_scope} embedding_option={segment.embedding_option} start_offset_sec={segment.start_offset_sec} end_offset_sec={segment.end_offset_sec}\")\n",
    "        first_few = segment.float_[:max_elements]\n",
    "        print(\n",
    "            f\"  embeddings: [{', '.join(str(x) for x in first_few)}...] (total: {len(segment.float_)} values)\"\n",
    "        )\n",
    "\n",
    "print_segments(video.embedding.video_embedding.segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3498c5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03818677, -0.06685268,  0.03037306, ...,  0.02135889,\n",
       "        0.03340793,  0.00982293], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_video_embeddings(index_id,video_id):\n",
    "    \"\"\"\n",
    "    Fetch segment embeddings for a video.\n",
    "    Each segment embedding is a list of floats.\n",
    "    \"\"\"\n",
    "    data = client.indexes.videos.retrieve(index_id, video_id, embedding_option=[\"visual-text\"])\n",
    "\n",
    "    #return data.embedding.video_embedding.segments[0].float_\n",
    "#     url = f\"{BASE_URL}/videos/{video_id}/embeddings\"\n",
    "#     resp = requests.get(url, headers=HEADERS)\n",
    "\n",
    "#     if resp.status_code != 200:\n",
    "#         raise Exception(f\"Failed to fetch embeddings for {video_id}: {resp.text}\")\n",
    "\n",
    "    \n",
    "    # Typically the response has a list of segments with embeddings and timestamps\n",
    "    segments = []\n",
    "    for seg in data.embedding.video_embedding.segments:\n",
    "        embedding = np.array(seg.float_, dtype=np.float32)\n",
    "        start_time = seg.start_offset_sec\n",
    "        end_time = seg.end_offset_sec\n",
    "        segments.append({\"embedding\": embedding, \"start\": start_time, \"end\": end_time})\n",
    "    return segments\n",
    "\n",
    "def get_video_level_embedding(index_id,video_id):\n",
    "    \"\"\"\n",
    "    If ad video has no segments, average its embeddings.\n",
    "    \"\"\"\n",
    "    segments = get_video_embeddings(index_id,video_id)\n",
    "    if not segments:\n",
    "        raise ValueError(f\"No embeddings returned for video {video_id}\")\n",
    "    all_embs = np.stack([s[\"embedding\"] for s in segments])\n",
    "    return np.mean(all_embs, axis=0)\n",
    "\n",
    "get_video_level_embedding(\"68e1830166ecb2513d7eee5f\",SPORTS_VIDEO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "09afed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "API_KEY = \"\"\n",
    "BASE_URL = \"https://api.twelvelabs.io/v1.3\"  # Check docs for latest version\n",
    "\n",
    "SPORTS_VIDEO_ID = \"68e1843366ecb2513d7eee87\"\n",
    "AD1_ID = \"68e1894217b39f617835d425\"\n",
    "AD2_ID = \"68e188e43a1b0bed6c13561e\"\n",
    "INDEX_ID = \"68e1830166ecb2513d7eee5f\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Helper functions\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "\n",
    "def score_similarity(segment_emb, ad_emb):\n",
    "    return float(cosine_similarity(segment_emb.reshape(1, -1), ad_emb.reshape(1, -1))[0][0])\n",
    "\n",
    "# ----------------------------\n",
    "# Main logic\n",
    "# ----------------------------\n",
    "\n",
    "sports_segments = get_video_embeddings(INDEX_ID,SPORTS_VIDEO_ID)\n",
    "ad1_embedding = get_video_level_embedding(INDEX_ID,AD1_ID)\n",
    "ad2_embedding = get_video_level_embedding(INDEX_ID,AD2_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "995c3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = {\n",
    "        \"Ad1\": ad1_embedding,\n",
    "        \"Ad2\": ad2_embedding,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "07fe3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seg in sports_segments:\n",
    "    for ad_name, ad_emb in ads.items():\n",
    "        score = score_similarity(seg[\"embedding\"], ad_emb)\n",
    "        results.append({\n",
    "                \"ad\": ad_name,\n",
    "                \"start\": seg[\"start\"],\n",
    "                \"end\": seg[\"end\"],\n",
    "                \"engagement_score\": round(score, 4)\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d9c14643",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda x: x[\"engagement_score\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cf255edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Top Recommended Ad Placements:\n",
      "🕐 0.0s - 8.0s → Ad1 (Engagement: 0.3305)\n",
      "🕐 0.0s - 8.0s → Ad2 (Engagement: 0.1572)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🏆 Top Recommended Ad Placements:\")\n",
    "for r in results[:10]:\n",
    "    print(f\"🕐 {r['start']}s - {r['end']}s → {r['ad']} (Engagement: {r['engagement_score']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "46fb77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.summarize(\n",
    "    video_id=AD2_ID,\n",
    "    type=\"summary\",\n",
    "    prompt=\"Summarise the video so that we put this AD in a video\",\n",
    "    temperature=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "931a4930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The video showcases a meticulous and elegant application of red lipstick, capturing the essence of a beauty routine with a focus on the subtle artistry involved. The scene opens with a close-up of a person's lips, highlighting the precision of the application process. A hand, adorned with light pink nail polish, delicately holds a brush and applies the vibrant red lipstick to the lower lip. The camera's close focus allows viewers to appreciate the gradual transformation as the lipstick is evenly distributed, resulting in a striking and polished look. This video, with its attention to detail and the serene application process, serves as an ideal backdrop for an advertisement, emphasizing the allure and sophistication of the featured lipstick.\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b457e480",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [125], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      3\u001b[0m cross_encoder \u001b[38;5;241m=\u001b[39m CrossEncoder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross-encoder/ms-marco-MiniLM-L-6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")  # compact + fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12920edc",
   "metadata": {},
   "outputs": [],
   "source": [
    " player in a white uniform, wearing number 7, receives the ball from a teammate and scores a goal against a goalkeeper in green.After scoring, the player runs towards the corner flag, celebrating his goal by taking off his shirt and raising his arms in triumph. The camera captures his jubilant expression and movements as he acknowledges the crowd's cheers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf319465",
   "metadata": {},
   "outputs": [],
   "source": [
    "The sneaker is shown from the side, focusing on the sole as it rotates to reveal the tread pattern.The camera angle shifts slightly to show the side profile of the shoe, highlighting the white color scheme and black laces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93236f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "The video starts with a close-up shot of a person's lips as a makeup brush with red lipstick begins to apply the product to the lower lip.The brush applies the last touches of lipstick to the upper lip, completing the application process. The video ends with the lips fully coated in red lipstick"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
